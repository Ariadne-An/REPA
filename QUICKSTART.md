# ğŸš€ SD1.5-REPA å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

**5 åˆ†é’Ÿå­¦ä¼šä½¿ç”¨ä½ è®­ç»ƒçš„æ¨¡å‹ï¼**

---

## ğŸ“ ä½ çš„æ¨¡å‹ä½ç½®

```
/workspace/REPA/models/sd15_repa_step24k/
â”œâ”€â”€ model.safetensors        # 4.0 GB - å•æ–‡ä»¶æ ¼å¼
â”œâ”€â”€ unet/                    # Diffusers æ ¼å¼
â”œâ”€â”€ vae/
â”œâ”€â”€ text_encoder/
â””â”€â”€ ...
```

---

## æ–¹æ³• 1: Python è„šæœ¬ (æœ€ç®€å•) â­

### åŸºç¡€ä½¿ç”¨

åˆ›å»ºä¸€ä¸ª Python æ–‡ä»¶ `generate.py`:

```python
from diffusers import StableDiffusionPipeline
import torch

# 1. åŠ è½½æ¨¡å‹
pipe = StableDiffusionPipeline.from_pretrained(
    "/workspace/REPA/models/sd15_repa_step24k",
    torch_dtype=torch.float16,
    safety_checker=None,
)
pipe = pipe.to("cuda")

# 2. ç”Ÿæˆå›¾ç‰‡
prompt = "a beautiful sunset over mountains, professional photography, 4k"

image = pipe(
    prompt=prompt,
    num_inference_steps=50,      # æ¨ç†æ­¥æ•° (25-100ï¼Œè¶Šå¤šè¶Šå¥½ä½†è¶Šæ…¢)
    guidance_scale=7.5,          # CFG scale (7-8.5 æ¨è)
    height=512,                  # é«˜åº¦
    width=512,                   # å®½åº¦
).images[0]

# 3. ä¿å­˜
image.save("output.png")
print("âœ… ç”Ÿæˆå®Œæˆï¼æŸ¥çœ‹ output.png")
```

**è¿è¡Œ**ï¼š
```bash
python generate.py
```

---

### è¿›é˜¶ç”¨æ³•ï¼šæ‰¹é‡ç”Ÿæˆ

```python
from diffusers import StableDiffusionPipeline
import torch
from PIL import Image

pipe = StableDiffusionPipeline.from_pretrained(
    "/workspace/REPA/models/sd15_repa_step24k",
    torch_dtype=torch.float16,
).to("cuda")

# æ‰¹é‡ç”Ÿæˆ 4 å¼ ä¸åŒçš„å›¾
prompts = [
    "a cute cat sitting on a window",
    "a professional photo of a dog",
    "a beautiful landscape with lake",
    "a modern architecture building",
]

for i, prompt in enumerate(prompts):
    image = pipe(
        prompt,
        num_inference_steps=30,
        guidance_scale=7.5,
        generator=torch.Generator("cuda").manual_seed(42 + i),  # å›ºå®šç§å­å¯å¤ç°
    ).images[0]

    image.save(f"output_{i+1}.png")
    print(f"âœ… ç”Ÿæˆ {i+1}/4")
```

---

### ä¼˜åŒ–ï¼šåŠ é€Ÿç”Ÿæˆ

```python
from diffusers import StableDiffusionPipeline
import torch

pipe = StableDiffusionPipeline.from_pretrained(
    "/workspace/REPA/models/sd15_repa_step24k",
    torch_dtype=torch.float16,
).to("cuda")

# ğŸš€ åŠ é€Ÿä¼˜åŒ–
# 1. xFormers (èŠ‚çœæ˜¾å­˜ï¼ŒåŠ é€Ÿ)
pipe.enable_xformers_memory_efficient_attention()

# 2. VAE slicing (èŠ‚çœæ˜¾å­˜)
pipe.enable_vae_slicing()

# 3. Attention slicing (è¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜)
pipe.enable_attention_slicing()

# ç°åœ¨ç”Ÿæˆä¼šæ›´å¿«ï¼Œæ˜¾å­˜å ç”¨æ›´å°‘
image = pipe(
    "a beautiful photo",
    num_inference_steps=25,  # å¯ä»¥ç”¨æ›´å°‘æ­¥æ•°
).images[0]

image.save("fast_output.png")
```

---

### é«˜çº§ï¼šæ§åˆ¶éšæœºæ€§

```python
import torch
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(
    "/workspace/REPA/models/sd15_repa_step24k",
    torch_dtype=torch.float16,
).to("cuda")

prompt = "a professional portrait photo"

# ç”Ÿæˆ 4 å¼ ä¸åŒç§å­çš„å›¾ç‰‡ï¼Œæ‰¾æœ€å¥½çš„
seeds = [42, 123, 456, 789]

for seed in seeds:
    generator = torch.Generator("cuda").manual_seed(seed)

    image = pipe(
        prompt,
        num_inference_steps=30,
        guidance_scale=7.5,
        generator=generator,
    ).images[0]

    image.save(f"output_seed_{seed}.png")

print("âœ… ç”Ÿæˆ 4 ä¸ªç§å­ï¼Œé€‰æ‹©ä½ æœ€å–œæ¬¢çš„ï¼")
```

---

## æ–¹æ³• 2: AUTOMATIC1111 WebUI ğŸ–¼ï¸

å¦‚æœä½ æœ‰ WebUI å®‰è£…ï¼š

### æ­¥éª¤ 1: å¤åˆ¶æ¨¡å‹

```bash
# æ‰¾åˆ°ä½ çš„ WebUI å®‰è£…è·¯å¾„
WEBUI_PATH="/path/to/stable-diffusion-webui"

# å¤åˆ¶æ¨¡å‹æ–‡ä»¶
cp /workspace/REPA/models/sd15_repa_step24k/model.safetensors \
   $WEBUI_PATH/models/Stable-diffusion/sd15_repa_step24k.safetensors
```

### æ­¥éª¤ 2: ä½¿ç”¨

1. å¯åŠ¨ WebUI
2. å·¦ä¸Šè§’ "Stable Diffusion checkpoint" â†’ é€‰æ‹© `sd15_repa_step24k`
3. è¾“å…¥ promptï¼Œç‚¹å‡» Generate

**æ¨èå‚æ•°**ï¼š
- Sampling Steps: 30-50
- CFG Scale: 7.0-8.0
- Sampling Method: DPM++ 2M Karras (æ¨è) æˆ– Euler a

---

## æ–¹æ³• 3: ComfyUI ğŸ¨

### æ­¥éª¤ 1: å¤åˆ¶æ¨¡å‹

```bash
COMFYUI_PATH="/path/to/ComfyUI"

cp /workspace/REPA/models/sd15_repa_step24k/model.safetensors \
   $COMFYUI_PATH/models/checkpoints/sd15_repa_step24k.safetensors
```

### æ­¥éª¤ 2: ä½¿ç”¨

1. åœ¨ ComfyUI ç•Œé¢ä¸­
2. æ‰¾åˆ° "Load Checkpoint" èŠ‚ç‚¹
3. é€‰æ‹© `sd15_repa_step24k.safetensors`
4. è¿æ¥åˆ°ä½ çš„å·¥ä½œæµ

---

## ğŸ“Š å‚æ•°è°ƒèŠ‚æŒ‡å—

### Inference Steps (æ¨ç†æ­¥æ•°)

| Steps | è´¨é‡ | é€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
|-------|------|------|---------|
| 20-25 | â­â­â­ | ğŸš€ğŸš€ğŸš€ | å¿«é€Ÿé¢„è§ˆ |
| 30-40 | â­â­â­â­ | ğŸš€ğŸš€ | **æ¨èæ—¥å¸¸ä½¿ç”¨** |
| 50-75 | â­â­â­â­â­ | ğŸš€ | é«˜è´¨é‡æœ€ç»ˆè¾“å‡º |
| 100+ | â­â­â­â­â­ | ğŸŒ | ç²¾ç»†è°ƒæ•´ |

**å»ºè®®**ï¼šä» 30 å¼€å§‹ï¼Œä¸æ»¡æ„å†å¢åŠ åˆ° 50ã€‚

---

### CFG Scale (Guidance Scale)

| CFG | æ•ˆæœ | é€‚ç”¨åœºæ™¯ |
|-----|------|---------|
| 3-5 | åˆ›æ„ã€å¤šæ ·æ€§é«˜ã€å¯èƒ½åç¦» prompt | è‰ºæœ¯åˆ›ä½œ |
| **7-8** | **å¹³è¡¡ï¼Œæ¨è** | **æ—¥å¸¸ä½¿ç”¨** |
| 9-12 | ä¸¥æ ¼éµå¾ª promptï¼Œå¯èƒ½è¿‡é¥±å’Œ | ç²¾ç¡®æ§åˆ¶ |
| 15+ | è¿‡åº¦é¥±å’Œï¼Œä¸è‡ªç„¶ | ä¸æ¨è |

**å»ºè®®**ï¼šé»˜è®¤ç”¨ 7.5ï¼Œå¦‚æœè§‰å¾—ä¸å¤Ÿå‡†ç¡®å°±è°ƒåˆ° 8.5ã€‚

---

### Negative Prompt (è´Ÿé¢æç¤ºè¯)

åŠ å…¥è´Ÿé¢ prompt å¯ä»¥æå‡è´¨é‡ï¼š

```python
image = pipe(
    prompt="a beautiful portrait photo",
    negative_prompt="ugly, blurry, low quality, distorted, bad anatomy",
    num_inference_steps=30,
    guidance_scale=7.5,
).images[0]
```

**æ¨èè´Ÿé¢è¯**ï¼š
```
ugly, blurry, low quality, low res, distorted, bad anatomy,
deformed, disfigured, watermark, text, signature
```

---

## ğŸ¯ å®æˆ˜ä¾‹å­

### ä¾‹å­ 1: äººç‰©è‚–åƒ

```python
prompt = """
a professional portrait photo of a young woman,
natural lighting, soft focus, high quality,
detailed face, photorealistic
"""

negative_prompt = """
ugly, blurry, low quality, bad anatomy,
deformed face, distorted features
"""

image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=50,
    guidance_scale=8.0,
    height=512,
    width=512,
).images[0]
```

---

### ä¾‹å­ 2: é£æ™¯ç…§ç‰‡

```python
prompt = """
a beautiful mountain landscape with lake,
golden hour lighting, professional photography,
8k, highly detailed, stunning colors
"""

negative_prompt = "low quality, blurry, distorted, watermark"

image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=40,
    guidance_scale=7.5,
    height=512,
    width=768,  # æ¨ªå‘æ„å›¾
).images[0]
```

---

### ä¾‹å­ 3: è‰ºæœ¯é£æ ¼

```python
prompt = """
a cat in the style of Van Gogh, oil painting,
impressionist, vibrant colors, masterpiece
"""

negative_prompt = "photorealistic, photograph, low quality"

image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=50,
    guidance_scale=9.0,  # æ›´é«˜çš„ CFG ç¡®ä¿é£æ ¼
).images[0]
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³ (OOM)

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# å¯ç”¨æ˜¾å­˜ä¼˜åŒ–
pipe.enable_attention_slicing()
pipe.enable_vae_slicing()

# æˆ–è€…é™ä½åˆ†è¾¨ç‡
image = pipe(prompt, height=448, width=448).images[0]
```

---

### Q2: ç”Ÿæˆé€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# 1. ä½¿ç”¨ fp16
pipe = pipe.to("cuda", dtype=torch.float16)

# 2. å¯ç”¨ xFormers
pipe.enable_xformers_memory_efficient_attention()

# 3. å‡å°‘æ­¥æ•°
image = pipe(prompt, num_inference_steps=25).images[0]
```

---

### Q3: ç”Ÿæˆè´¨é‡ä¸æ»¡æ„

**è°ƒæ•´ç­–ç•¥**ï¼š

1. **Prompt ä¸å¤Ÿå¥½**ï¼š
   - æ·»åŠ æ›´å¤šç»†èŠ‚æè¿°
   - ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼ˆå¦‚ "professional photography", "highly detailed"ï¼‰
   - å‚è€ƒæˆåŠŸçš„ prompt èŒƒä¾‹

2. **å‚æ•°ä¸åˆé€‚**ï¼š
   - å¢åŠ æ­¥æ•°ï¼š30 â†’ 50
   - è°ƒæ•´ CFGï¼š7.5 â†’ 8.5
   - æ·»åŠ  negative prompt

3. **ç§å­é—®é¢˜**ï¼š
   - å°è¯•å¤šä¸ªä¸åŒç§å­ï¼ˆ42, 123, 456...ï¼‰
   - é€‰æ‹©æœ€å¥½çš„ç»“æœ

---

### Q4: èƒ½å¦ç”Ÿæˆæ›´å¤§åˆ†è¾¨ç‡ï¼Ÿ

SD1.5 è®­ç»ƒåœ¨ 512Ã—512ï¼Œä½†å¯ä»¥ç”Ÿæˆæ›´å¤§ï¼š

```python
# æ–¹æ³• 1: ç›´æ¥ç”Ÿæˆ (å¯èƒ½æœ‰é‡å¤)
image = pipe(prompt, height=768, width=768).images[0]

# æ–¹æ³• 2: ç”Ÿæˆåæ”¾å¤§ (æ¨è)
small = pipe(prompt, height=512, width=512).images[0]

# ä½¿ç”¨ upscaler (éœ€è¦é¢å¤–å®‰è£…)
from PIL import Image
large = small.resize((1024, 1024), Image.LANCZOS)
large.save("large_output.png")
```

---

## ğŸ’¡ Pro Tips

### Tip 1: ä¿å­˜é…ç½®

æŠŠä½ å–œæ¬¢çš„é…ç½®ä¿å­˜ä¸‹æ¥ï¼š

```python
# config.py
DEFAULT_CONFIG = {
    "num_inference_steps": 40,
    "guidance_scale": 7.5,
    "height": 512,
    "width": 512,
    "negative_prompt": "ugly, blurry, low quality",
}

# ä½¿ç”¨
image = pipe(prompt="your prompt", **DEFAULT_CONFIG).images[0]
```

---

### Tip 2: æ‰¹é‡å¤„ç†

```python
import os
from tqdm import tqdm

prompts = [
    "prompt 1",
    "prompt 2",
    "prompt 3",
    # ... æ›´å¤š
]

output_dir = "outputs"
os.makedirs(output_dir, exist_ok=True)

for i, prompt in enumerate(tqdm(prompts)):
    image = pipe(prompt, num_inference_steps=30).images[0]
    image.save(f"{output_dir}/image_{i:03d}.png")
```

---

### Tip 3: Prompt æ¨¡æ¿

```python
TEMPLATES = {
    "portrait": "a professional portrait photo of {subject}, natural lighting, high quality",
    "landscape": "a beautiful {subject} landscape, golden hour, professional photography",
    "art": "{subject} in the style of {artist}, masterpiece, highly detailed",
}

# ä½¿ç”¨
prompt = TEMPLATES["portrait"].format(subject="a young woman")
image = pipe(prompt).images[0]
```

---

## ğŸ¨ åˆ›æ„ç¤ºä¾‹

### ç”Ÿæˆç½‘æ ¼å¯¹æ¯”

```python
from PIL import Image

prompts = ["cat", "dog", "bird", "fish"]
images = []

for prompt in prompts:
    img = pipe(f"a photo of a {prompt}", num_inference_steps=30).images[0]
    images.append(img)

# åˆ›å»º 2x2 ç½‘æ ¼
grid = Image.new('RGB', (1024, 1024))
for i, img in enumerate(images):
    x = (i % 2) * 512
    y = (i // 2) * 512
    grid.paste(img, (x, y))

grid.save("grid.png")
```

---

## ğŸ“š ä¸‹ä¸€æ­¥

å­¦ä¼šåŸºç¡€ä½¿ç”¨åï¼Œä½ å¯ä»¥ï¼š

1. **æ¢ç´¢ LoRA**ï¼šåœ¨ä½ çš„æ¨¡å‹åŸºç¡€ä¸Šå†åŠ  LoRA
2. **å°è¯• ControlNet**ï¼šç²¾ç¡®æ§åˆ¶æ„å›¾
3. **Img2Img**ï¼šå›¾ç”Ÿå›¾åŠŸèƒ½
4. **Inpainting**ï¼šå±€éƒ¨ä¿®å¤

---

## ğŸ†˜ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨ï¼š`torch.cuda.is_available()`
2. æŸ¥çœ‹æ˜¾å­˜å ç”¨ï¼š`nvidia-smi`
3. å°è¯•ç¤ºä¾‹è„šæœ¬ï¼š`python test_converted_model.py`

---

**ğŸ‰ å¼€å§‹åˆ›ä½œå§ï¼**

è®°ä½ï¼š
- ä»ç®€å•çš„ prompt å¼€å§‹
- å¤šå°è¯•ä¸åŒå‚æ•°
- ä¿å­˜å¥½çš„é…ç½®
- æœ€é‡è¦çš„æ˜¯ï¼šç©å¾—å¼€å¿ƒï¼
