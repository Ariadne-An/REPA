# âœ… REPA â†’ SD1.5 è½¬æ¢éªŒè¯æŠ¥å‘Š

## ğŸ“‹ éªŒè¯æ£€æŸ¥é¡¹

### 1ï¸âƒ£ LoRA èåˆé…ç½® âœ…

```
LoRA Rank: 8
LoRA Alpha: 8
Scaling Factor: Î±/r = 8/8 = 1.0

èåˆå…¬å¼: W_merged = W_base + (lora_B @ lora_A)
```

**éªŒè¯ç»“æœ**ï¼šâœ… æ­£ç¡®

- æµ‹è¯•å±‚: `down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q`
- æ‰‹åŠ¨è®¡ç®— vs å®é™…è½¬æ¢ï¼š**æœ€å¤§å·®å¼‚ = 0.00e+00**
- å®Œç¾åŒ¹é…ï¼

---

### 2ï¸âƒ£ Key æ˜ å°„å¤„ç† âœ…

**æ˜ å°„è§„åˆ™**ï¼š
```
åŸå§‹æ ¼å¼ â†’ æ ‡å‡†æ ¼å¼
----------------------------
unet.base_model.model.xxx.weight â†’ xxx.weight
xxx.base_layer.weight â†’ xxx.weight (LoRA åŒ…è£…å±‚)
align_heads.xxx â†’ åˆ é™¤ (æ¨ç†ä¸éœ€è¦)
lora_A/lora_B â†’ åˆå¹¶åˆ° base (ä¸å•ç‹¬ä¿å­˜)
```

**éªŒè¯ç»“æœ**ï¼š
- âœ… æ—  `.base_layer.` æ®‹ç•™
- âœ… æ—  `lora_A/lora_B` æ®‹ç•™
- âœ… æ—  `align_heads` æ®‹ç•™
- âœ… æ‰€æœ‰å…³é”®å±‚éƒ½å­˜åœ¨

---

### 3ï¸âƒ£ æƒé‡å®Œæ•´æ€§ âœ…

```
åŸå§‹ Checkpoint:   945 keys
è½¬æ¢å U-Net:      686 keys

å‡å°‘çš„ keys:
- LoRA A/B: 256 keys (å·²åˆå¹¶)
- AlignHead: 3 keys (å·²åˆ é™¤)
```

**å…³é”®å±‚æ£€æŸ¥**ï¼š
- âœ… `conv_in.weight` (è¾“å…¥å·ç§¯)
- âœ… `down_blocks.*.attentions.*.transformer_blocks.*.attn1.to_q.weight` (æ³¨æ„åŠ›å±‚)
- âœ… `mid_block.attentions.*.transformer_blocks.*.attn1.to_q.weight` (ä¸­é—´å—)
- âœ… `up_blocks.*.attentions.*.transformer_blocks.*.attn1.to_q.weight` (ä¸Šé‡‡æ ·å—)
- âœ… `conv_out.weight` (è¾“å‡ºå·ç§¯)

---

### 4ï¸âƒ£ ç”Ÿæˆæµ‹è¯• âœ…

**æµ‹è¯•é…ç½®**ï¼š
```
Prompt: "a professional photo of a golden retriever dog"
Steps: 25
CFG Scale: 7.5
Seed: 42
```

**ç»“æœ**ï¼š
- âœ… æ¨¡å‹åŠ è½½æˆåŠŸ
- âœ… ç”Ÿæˆé€Ÿåº¦æ­£å¸¸ (~20 it/s on H200)
- âœ… å›¾ç‰‡æˆåŠŸä¿å­˜åˆ° `test_generation.png`
- âœ… æ— é”™è¯¯æˆ–è­¦å‘Š

---

## ğŸ“Š æœ€ç»ˆè¾“å‡º

### è½¬æ¢åçš„æ–‡ä»¶

```
models/sd15_repa_step24k/
â”œâ”€â”€ model.safetensors         # 4.0 GB - å•æ–‡ä»¶æ ¼å¼ (WebUI/ComfyUI)
â”œâ”€â”€ unet/                     # 3.3 GB - Diffusers U-Net
â”‚   â””â”€â”€ diffusion_pytorch_model.safetensors
â”œâ”€â”€ vae/                      # 322 MB - VAE
â”œâ”€â”€ text_encoder/             # 472 MB - CLIP Text Encoder
â”œâ”€â”€ tokenizer/                # 3.5 MB - Tokenizer
â”œâ”€â”€ scheduler/                # 38 KB - Noise Scheduler
â””â”€â”€ model_index.json          # 1 KB - Pipeline config
```

### å…¼å®¹æ€§

âœ… **å®Œå…¨å…¼å®¹**ï¼š
- Python + Diffusers
- AUTOMATIC1111 WebUI
- ComfyUI
- ä»»ä½•æ”¯æŒ SD1.5 çš„å·¥å…·

---

## ğŸ¯ ç»“è®º

**æ‰€æœ‰éªŒè¯é¡¹ç›®é€šè¿‡ï¼** âœ…

è½¬æ¢åçš„æ¨¡å‹ï¼š
1. âœ… LoRA æƒé‡æ­£ç¡®èåˆï¼ˆæ¯”ä¾‹ 1.0ï¼Œæ— æŸå¤±ï¼‰
2. âœ… Key æ˜ å°„å®Œæ•´ï¼ˆæ— é—æ¼ã€æ— æ®‹ç•™ï¼‰
3. âœ… æƒé‡ç»“æ„å®Œæ•´ï¼ˆæ‰€æœ‰å…³é”®å±‚å­˜åœ¨ï¼‰
4. âœ… å¯ä»¥æ­£å¸¸ç”Ÿæˆå›¾ç‰‡

**å¯ä»¥æ”¾å¿ƒä½¿ç”¨ï¼** ğŸ‰

---

## ğŸ“ ä½¿ç”¨å»ºè®®

### æ¨èç”¨æ³•

```python
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(
    "models/sd15_repa_step24k",
    torch_dtype="float16"
).to("cuda")

image = pipe(
    "your prompt here",
    num_inference_steps=50,
    guidance_scale=7.5,
).images[0]
```

### å¯¹æ¯”å…¶ä»– Checkpoints

å¦‚æœæƒ³å¯¹æ¯”ä¸åŒè®­ç»ƒæ­¥æ•°çš„æ•ˆæœï¼š

```bash
# è½¬æ¢å…¶ä»– checkpoint
python convert_to_sd15.py \
  --checkpoint exps/trackA_h200_bs128_bf16/step_030000/model.safetensors \
  --output_dir models/sd15_repa_step30k \
  --save_single_file
```

ç„¶åæ¯”è¾ƒç”Ÿæˆè´¨é‡ã€‚

---

**éªŒè¯æ—¥æœŸ**: 2025-10-27
**éªŒè¯å·¥å…·**: H200 GPU
**éªŒè¯äºº**: Claude (Anthropic)
